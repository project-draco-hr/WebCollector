{
  ArrayList<URLCrawlDatum> list=new ArrayList<URLCrawlDatum>();
  list.add(new URLCrawlDatum(new Text("http://www.example.com"),new CrawlDatum(CrawlDatum.STATUS_DB_GONE,0,0.0f)));
  list.add(new URLCrawlDatum(new Text("http://www.example1.com"),new CrawlDatum(CrawlDatum.STATUS_DB_FETCHED,0,0.0f)));
  list.add(new URLCrawlDatum(new Text("http://www.example2.com"),new CrawlDatum(CrawlDatum.STATUS_DB_UNFETCHED,0,0.0f)));
  dbDir=new Path(testdir,"crawldb");
  newCrawlDb=new Path(testdir,"newcrawldb");
  CrawlDBTestUtil.createCrawlDb(conf,fs,dbDir,list);
  conf.setBoolean(CrawlDb.CRAWLDB_PURGE_404,true);
  conf.setBoolean(CrawlDbFilter.URL_NORMALIZING,true);
  conf.setBoolean(CrawlDbFilter.URL_FILTERING,false);
  conf.setInt("urlnormalizer.loop.count",2);
  JobConf job=new NutchJob(conf);
  job.setJobName("Test CrawlDbFilter");
  Path current=new Path(dbDir,"current");
  if (FileSystem.get(job).exists(current)) {
    FileInputFormat.addInputPath(job,current);
  }
  job.setInputFormat(SequenceFileInputFormat.class);
  job.setMapperClass(CrawlDbFilter.class);
  job.setReducerClass(CrawlDbReducer.class);
  FileOutputFormat.setOutputPath(job,newCrawlDb);
  job.setOutputFormat(MapFileOutputFormat.class);
  job.setOutputKeyClass(Text.class);
  job.setOutputValueClass(CrawlDatum.class);
  JobClient.runJob(job);
  Path fetchlist=new Path(new Path(newCrawlDb,"part-00000"),"data");
  ArrayList<URLCrawlDatum> l=readContents(fetchlist);
  Assert.assertEquals(2,l.size());
}
