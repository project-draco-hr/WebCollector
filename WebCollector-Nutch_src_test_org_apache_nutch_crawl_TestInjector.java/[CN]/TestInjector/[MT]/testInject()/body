{
  ArrayList<String> urls=new ArrayList<String>();
  ArrayList<String> metadata=new ArrayList<String>();
  for (int i=0; i < 100; i++) {
    urls.add("http://zzz.com/" + i + ".html");
    metadata.add("\tnutch.score=2." + i + "\tnutch.fetchInterval=171717\tkey=value");
  }
  CrawlDBTestUtil.generateSeedList(fs,urlPath,urls,metadata);
  Injector injector=new Injector(conf);
  injector.inject(crawldbPath,urlPath);
  List<String> read=readCrawldb();
  Collections.sort(read);
  Collections.sort(urls);
  Assert.assertEquals(urls.size(),read.size());
  Assert.assertTrue(read.containsAll(urls));
  Assert.assertTrue(urls.containsAll(read));
  ArrayList<String> urls2=new ArrayList<String>();
  for (int i=0; i < 100; i++) {
    urls2.add("http://xxx.com/" + i + ".html");
    urls2.add("http://zzz.com/" + i + ".html");
  }
  CrawlDBTestUtil.generateSeedList(fs,urlPath,urls2);
  injector=new Injector(conf);
  conf.setBoolean("db.injector.update",true);
  injector.inject(crawldbPath,urlPath);
  urls.addAll(urls2);
  read=readCrawldb();
  Collections.sort(read);
  Collections.sort(urls);
  Assert.assertEquals(urls.size() - 100,read.size());
  Assert.assertTrue(read.containsAll(urls));
  Assert.assertTrue(urls.containsAll(read));
  Map<String,CrawlDatum> records=readCrawldbRecords();
  Text writableKey=new Text("key");
  Text writableValue=new Text("value");
  for (  String url : urls) {
    if (url.indexOf("http://zzz") == 0) {
      Assert.assertTrue(records.get(url).getFetchInterval() == 171717);
      Assert.assertTrue(records.get(url).getScore() != 1.0);
      Assert.assertEquals(writableValue,records.get(url).getMetaData().get(writableKey));
    }
  }
}
