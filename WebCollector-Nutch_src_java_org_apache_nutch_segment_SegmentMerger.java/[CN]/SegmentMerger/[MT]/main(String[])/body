{
  if (args.length < 2) {
    System.err.println("SegmentMerger output_dir (-dir segments | seg1 seg2 ...) [-filter] [-slice NNNN]");
    System.err.println("\toutput_dir\tname of the parent dir for output segment slice(s)");
    System.err.println("\t-dir segments\tparent dir containing several segments");
    System.err.println("\tseg1 seg2 ...\tlist of segment dirs");
    System.err.println("\t-filter\t\tfilter out URL-s prohibited by current URLFilters");
    System.err.println("\t-normalize\t\tnormalize URL via current URLNormalizers");
    System.err.println("\t-slice NNNN\tcreate many output segments, each containing NNNN URLs");
    return;
  }
  Configuration conf=NutchConfiguration.create();
  final FileSystem fs=FileSystem.get(conf);
  Path out=new Path(args[0]);
  ArrayList<Path> segs=new ArrayList<Path>();
  long sliceSize=0;
  boolean filter=false;
  boolean normalize=false;
  for (int i=1; i < args.length; i++) {
    if (args[i].equals("-dir")) {
      FileStatus[] fstats=fs.listStatus(new Path(args[++i]),HadoopFSUtil.getPassDirectoriesFilter(fs));
      Path[] files=HadoopFSUtil.getPaths(fstats);
      for (int j=0; j < files.length; j++)       segs.add(files[j]);
    }
 else     if (args[i].equals("-filter")) {
      filter=true;
    }
 else     if (args[i].equals("-normalize")) {
      normalize=true;
    }
 else     if (args[i].equals("-slice")) {
      sliceSize=Long.parseLong(args[++i]);
    }
 else {
      segs.add(new Path(args[i]));
    }
  }
  if (segs.size() == 0) {
    System.err.println("ERROR: No input segments.");
    return;
  }
  SegmentMerger merger=new SegmentMerger(conf);
  merger.merge(out,segs.toArray(new Path[segs.size()]),filter,normalize,sliceSize);
}
